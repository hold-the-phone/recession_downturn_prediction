{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reg_ready.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>monthly_return</th>\n",
       "      <th>period of downturn</th>\n",
       "      <th>Recessions</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>yc_date</th>\n",
       "      <th>YIELD_CURVE</th>\n",
       "      <th>UNEMPLOYMENT</th>\n",
       "      <th>BGI_diff_from_2_month_high</th>\n",
       "      <th>KO_diff_from_2_month_high</th>\n",
       "      <th>KR_diff_from_2_month_high</th>\n",
       "      <th>MAR_diff_from_2_month_high</th>\n",
       "      <th>PPG_diff_from_2_month_high</th>\n",
       "      <th>SHW_diff_from_2_month_high</th>\n",
       "      <th>unemployment_diff_from_6_month_low</th>\n",
       "      <th>INDPRO_diff_from_6_month_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362</td>\n",
       "      <td>1980-04-01</td>\n",
       "      <td>102.089996</td>\n",
       "      <td>106.290001</td>\n",
       "      <td>0.041140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.5053</td>\n",
       "      <td>1980-04-01</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.041825</td>\n",
       "      <td>-0.053846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363</td>\n",
       "      <td>1980-05-01</td>\n",
       "      <td>106.290001</td>\n",
       "      <td>111.239998</td>\n",
       "      <td>0.046571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.3294</td>\n",
       "      <td>1980-05-01</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>364</td>\n",
       "      <td>1980-06-01</td>\n",
       "      <td>111.239998</td>\n",
       "      <td>114.239998</td>\n",
       "      <td>0.026969</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.2336</td>\n",
       "      <td>1980-06-02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.068085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365</td>\n",
       "      <td>1980-07-01</td>\n",
       "      <td>114.239998</td>\n",
       "      <td>121.669998</td>\n",
       "      <td>0.065039</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.9638</td>\n",
       "      <td>1980-07-01</td>\n",
       "      <td>1.12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366</td>\n",
       "      <td>1980-08-01</td>\n",
       "      <td>121.669998</td>\n",
       "      <td>122.379997</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.3348</td>\n",
       "      <td>1980-08-01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.1705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Date        Open       Close  monthly_return  \\\n",
       "0    362 1980-04-01  102.089996  106.290001        0.041140   \n",
       "1    363 1980-05-01  106.290001  111.239998        0.046571   \n",
       "2    364 1980-06-01  111.239998  114.239998        0.026969   \n",
       "3    365 1980-07-01  114.239998  121.669998        0.065039   \n",
       "4    366 1980-08-01  121.669998  122.379997        0.005835   \n",
       "\n",
       "   period of downturn  Recessions   INDPRO     yc_date  YIELD_CURVE  \\\n",
       "0                   0           1  53.5053  1980-04-01        -1.90   \n",
       "1                   0           1  53.3294  1980-05-01        -0.13   \n",
       "2                   0           1  52.2336  1980-06-02         0.97   \n",
       "3                   0           1  50.9638  1980-07-01         1.12   \n",
       "4                   0           1  50.3348  1980-08-01         0.98   \n",
       "\n",
       "   UNEMPLOYMENT  BGI_diff_from_2_month_high  KO_diff_from_2_month_high  \\\n",
       "0           6.3                         NaN                  -0.041825   \n",
       "1           6.3                         NaN                   0.000000   \n",
       "2           6.9                         NaN                   0.000000   \n",
       "3           7.5                         NaN                  -0.022222   \n",
       "4           7.6                         NaN                   0.000000   \n",
       "\n",
       "   KR_diff_from_2_month_high  MAR_diff_from_2_month_high  \\\n",
       "0                  -0.053846                         NaN   \n",
       "1                   0.000000                         NaN   \n",
       "2                   0.000000                         NaN   \n",
       "3                   0.000000                         NaN   \n",
       "4                   0.000000                         NaN   \n",
       "\n",
       "   PPG_diff_from_2_month_high  SHW_diff_from_2_month_high  \\\n",
       "0                    0.000000                    0.000000   \n",
       "1                    0.000000                    0.000000   \n",
       "2                    0.000000                   -0.068085   \n",
       "3                   -0.008264                    0.000000   \n",
       "4                    0.000000                    0.000000   \n",
       "\n",
       "   unemployment_diff_from_6_month_low  INDPRO_diff_from_6_month_high  \n",
       "0                                 0.4                         0.0000  \n",
       "1                                 0.4                         0.1759  \n",
       "2                                 1.0                         1.2717  \n",
       "3                                 1.5                         2.5415  \n",
       "4                                 1.3                         3.1705  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REL_VARS = ['YIELD_CURVE','KO_diff_from_2_month_high',\n",
    "       'KR_diff_from_2_month_high',\n",
    "       'PPG_diff_from_2_month_high', 'SHW_diff_from_2_month_high',\n",
    "       'unemployment_diff_from_6_month_low', 'INDPRO_diff_from_6_month_high']\n",
    "\n",
    "\n",
    "\n",
    "df.dropna(subset=REL_VARS,inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create windows of proper dimension (samples X timesteps X features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y_downturn = []\n",
    "y_monthly_return = []\n",
    "\n",
    "for idx,dt in enumerate(df['Date']):\n",
    "    obs_prior = df[df['Date']<=dt].shape[0]\n",
    "    if obs_prior>=12:\n",
    "        sample = []\n",
    "        df_last_12 = df[df['Date']<=dt].iloc[-12:]\n",
    "        sample.append(list(df_last_12['YIELD_CURVE']))\n",
    "        sample.append(list(df_last_12['KO_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['KR_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['PPG_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['SHW_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['unemployment_diff_from_6_month_low']))\n",
    "        sample.append(list(df_last_12['INDPRO_diff_from_6_month_high']))\n",
    "        sample = np.array(sample).T\n",
    "        \n",
    "        X.append(sample)\n",
    "        y_downturn.append(df.iloc[idx]['period of downturn'])\n",
    "        y_monthly_return.append(df.iloc[idx]['monthly_return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 12, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.array(X)\n",
    "arr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 19)\n",
      "(176, 19)\n"
     ]
    }
   ],
   "source": [
    "df_train = df.iloc[11:296]\n",
    "print(df_train.shape)\n",
    "df_test = df.iloc[297:]\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with predicting monthly return on 1980 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_monthly_return)\n",
    "X = arr1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 12, 7)\n",
      "(176, 12, 7)\n"
     ]
    }
   ],
   "source": [
    "trainX = X[:285,:,:]\n",
    "trainY = y[:285]\n",
    "\n",
    "testX = X[286:,:,:]\n",
    "testY = y[286:]\n",
    "print(trainX.shape)\n",
    "print(testX.shape)  ##We can see that the dimensions of the numpy arrays are what we expected for merging with dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 14:22:58.066321 140737112867776 deprecation_wrapper.py:119] From /Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0814 14:22:58.182993 140737112867776 deprecation_wrapper.py:119] From /Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0814 14:22:58.213577 140737112867776 deprecation_wrapper.py:119] From /Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0814 14:22:58.949818 140737112867776 deprecation_wrapper.py:119] From /Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "features=7\n",
    "timesteps=12\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(LSTM(4, batch_input_shape=(batch_size, timesteps, features), return_sequences=True,activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LSTM(16, batch_input_shape=(batch_size, timesteps, features), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (1, 16)                   1536      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, 1)                    17        \n",
      "=================================================================\n",
      "Total params: 1,553\n",
      "Trainable params: 1,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 14:22:59.146584 140737112867776 deprecation.py:323] From /Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0814 14:22:59.423761 140737112867776 deprecation_wrapper.py:119] From /Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0814 14:22:59.493442 140737112867776 deprecation_wrapper.py:119] From /Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 176 samples\n",
      "Epoch 1/15\n",
      " - 2s - loss: 0.0062 - val_loss: 0.0642\n",
      "Epoch 2/15\n",
      " - 2s - loss: 0.0024 - val_loss: 0.0627\n",
      "Epoch 3/15\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0467\n",
      "Epoch 4/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0441\n",
      "Epoch 5/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0387\n",
      "Epoch 6/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0364\n",
      "Epoch 7/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0314\n",
      "Epoch 8/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0297\n",
      "Epoch 9/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0251\n",
      "Epoch 10/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0211\n",
      "Epoch 11/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0208\n",
      "Epoch 12/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0173\n",
      "Epoch 13/15\n",
      " - 2s - loss: 0.0018 - val_loss: 0.0155\n",
      "Epoch 14/15\n",
      " - 2s - loss: 0.0018 - val_loss: 0.0143\n",
      "Epoch 15/15\n",
      " - 2s - loss: 0.0018 - val_loss: 0.0129\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(trainX, trainY, epochs=15, batch_size=batch_size, verbose=2, shuffle=False,validation_data=[testX,testY])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['pred'] = trainPredict\n",
    "df_train.to_csv('trainset_LSTM_1980.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['pred'] = testPredict\n",
    "df_test.to_csv('testset_LSTM_1980.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us try with downturn classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 12, 7)\n",
      "(176, 12, 7)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y_downturn)\n",
    "X = arr1.copy()\n",
    "\n",
    "trainX = X[:285,:,:]\n",
    "trainY = y[:285]\n",
    "\n",
    "testX = X[286:,:,:]\n",
    "testY = y[286:]\n",
    "print(trainX.shape)\n",
    "print(testX.shape)  ##We can see that the dimensions of the numpy arrays are what we expected for merging with dfs.\n",
    "\n",
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "features=7\n",
    "timesteps=12\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(LSTM(4, batch_input_shape=(batch_size, timesteps, features), return_sequences=True,activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LSTM(16, batch_input_shape=(batch_size, timesteps, features), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 176 samples\n",
      "Epoch 1/7\n",
      " - 2s - loss: 0.7739 - val_loss: 1.3241\n",
      "Epoch 2/7\n",
      " - 2s - loss: 0.9152 - val_loss: 1.3070\n",
      "Epoch 3/7\n",
      " - 2s - loss: 0.9136 - val_loss: 1.3098\n",
      "Epoch 4/7\n",
      " - 2s - loss: 0.5726 - val_loss: 0.4497\n",
      "Epoch 5/7\n",
      " - 2s - loss: 0.4279 - val_loss: 0.4309\n",
      "Epoch 6/7\n",
      " - 2s - loss: 0.3523 - val_loss: 0.6802\n",
      "Epoch 7/7\n",
      " - 2s - loss: 0.2945 - val_loss: 0.6741\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(trainX, trainY, epochs=7, batch_size=batch_size, verbose=2, shuffle=False,validation_data=[testX,testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['pred'] = testPredict\n",
    "#df_test.to_csv('testset_LSTM_classification_1980.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try with fewer features - 1980, drop KO,KR, and monthly_return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 19)\n",
      "(176, 19)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y_downturn = []\n",
    "y_monthly_return = []\n",
    "\n",
    "for idx,dt in enumerate(df['Date']):\n",
    "    obs_prior = df[df['Date']<=dt].shape[0]\n",
    "    if obs_prior>=12:\n",
    "        sample = []\n",
    "        df_last_12 = df[df['Date']<=dt].iloc[-12:]\n",
    "        sample.append(list(df_last_12['YIELD_CURVE']))\n",
    "        #sample.append(list(df_last_12['KO_diff_from_2_month_high']))\n",
    "        #sample.append(list(df_last_12['KR_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['PPG_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['SHW_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['unemployment_diff_from_6_month_low']))\n",
    "        sample.append(list(df_last_12['INDPRO_diff_from_6_month_high']))\n",
    "        sample = np.array(sample).T\n",
    "        \n",
    "        X.append(sample)\n",
    "        y_downturn.append(df.iloc[idx]['period of downturn'])\n",
    "        y_monthly_return.append(df.iloc[idx]['monthly_return'])\n",
    "        \n",
    "arr1 = np.array(X)\n",
    "arr1.shape\n",
    "\n",
    "df_train = df.iloc[11:296]\n",
    "print(df_train.shape)\n",
    "df_test = df.iloc[297:]\n",
    "print(df_test.shape)\n",
    "\n",
    "y = np.array(y_monthly_return)\n",
    "X = arr1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 12, 5)\n",
      "(176, 12, 5)\n"
     ]
    }
   ],
   "source": [
    "trainX = X[:285,:,:]\n",
    "trainY = y[:285]\n",
    "\n",
    "testX = X[286:,:,:]\n",
    "testY = y[286:]\n",
    "print(trainX.shape)\n",
    "print(testX.shape)  ##We can see that the dimensions of the numpy arrays are what we expected for merging with dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "features=5\n",
    "timesteps=12\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(16, batch_input_shape=(batch_size, timesteps, features), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 176 samples\n",
      "Epoch 1/15\n",
      " - 2s - loss: 0.0027 - val_loss: 0.0077\n",
      "Epoch 2/15\n",
      " - 2s - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 3/15\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 4/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 5/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 6/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 7/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 8/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 9/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 10/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 11/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 12/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 13/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 14/15\n",
      " - 2s - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 15/15\n",
      " - 2s - loss: 0.0018 - val_loss: 0.0025\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(trainX, trainY, epochs=15, batch_size=batch_size, verbose=2, shuffle=False,validation_data=[testX,testY])\n",
    "\n",
    "#trainPredict = model.predict(trainX, batch_size=batch_size)\n",
    "#df_train['pred'] = trainPredict\n",
    "#df_train.to_csv('trainset_LSTM_1980_reducedfeats.csv',index=False)\n",
    "#\n",
    "#testPredict = model.predict(testX, batch_size=batch_size)\n",
    "#df_test['pred'] = testPredict\n",
    "#df_test.to_csv('testset_LSTM_1980_reducedfeats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So the 1980 full features is the best (or equivalent) of the RNN models tried. Let's comment out the extra to simplify file mgmt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not better (although more sensitive) than classification RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
